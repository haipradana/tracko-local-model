{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Action Recognition Model for TRACKO - VideoMAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notebook ini merupakan notebook development untuk mencoba dan memvalidasi model secara lokal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pipeline:\n",
        "1. Input video → YOLO detection → create bounding boxes for each person\n",
        "2. Extract person clips → predict actions using trained model  \n",
        "3. Post-processing: Filter out short duration events (<0.4s) to remove unstable predictions\n",
        "4. Export results to CSV and annotated video\n",
        "\n",
        "Requirements:\n",
        "- Input video: sample_video/video.mp4\n",
        "- Output: annotated video + action summary CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Instalasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaFSJjthP9O3",
        "outputId": "7c6c91ad-5a11-432b-92c7-cf88c3c45759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoModelForVideoClassification\n",
        "from ultralytics import YOLO\n",
        "from decord import VideoReader, cpu\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "from IPython.display import HTML, display\n",
        "from base64 import b64encode\n",
        "from collections import defaultdict\n",
        "import csv\n",
        "\n",
        "# Load utilities\n",
        "from action_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run #001\n",
            "Output folder: hasil/001\n",
            "Video output: hasil/001/videomae_prediction.mp4\n",
            "CSV output: hasil/001/videomae_rekap.csv\n"
          ]
        }
      ],
      "source": [
        "# Generate path for saving results\n",
        "current_run = get_next_run_number()\n",
        "run_folder = f\"hasil/{current_run:03d}\"\n",
        "os.makedirs(run_folder, exist_ok=True)\n",
        "\n",
        "input_video_path = \"../sample_video/sample.mp4\"\n",
        "output_video_path = f\"{run_folder}/videomae_prediction.mp4\"\n",
        "output_csv_path = f\"{run_folder}/videomae_rekap.csv\"\n",
        "\n",
        "print(f\"Run #{current_run:03d}\")\n",
        "print(f\"Output folder: {run_folder}\")\n",
        "print(f\"Video output: {output_video_path}\")\n",
        "print(f\"CSV output: {output_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CYqvcfNaQDj7",
        "outputId": "00ca198c-1ce9-451e-af61-985e0a59add0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 103MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "YOLO(\n",
              "  (model): DetectionModel(\n",
              "    (model): Sequential(\n",
              "      (0): Conv(\n",
              "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (2): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Conv(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (4): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (6): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Conv(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (8): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SPPF(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (10): C2PSA(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): Sequential(\n",
              "          (0): PSABlock(\n",
              "            (attn): Attention(\n",
              "              (qkv): Conv(\n",
              "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (proj): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (pe): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "            (ffn): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (12): Concat()\n",
              "      (13): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (15): Concat()\n",
              "      (16): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (17): Conv(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (18): Concat()\n",
              "      (19): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (20): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (21): Concat()\n",
              "      (22): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (23): Detect(\n",
              "        (cv2): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (cv3): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (dfl): DFL(\n",
              "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# VideoMAE Action Recognition Model for TRACKO\n",
        "MODEL_PATH = \"haipradana/tracko-videomae-action-detection\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "yolo_model = YOLO(\"yolo11n.pt\")\n",
        "yolo_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d4fd3468a21c4ae5bed31ebcfe6cd77a",
            "a5fa8af208ea4c08bfd926138d1a7555",
            "6370bef713af40b1a51158378fe6ec02",
            "63ecf458d5584859aebd5606183e9569",
            "ad65c5c0f1fa48e8816ee95297e1fac9",
            "4d63ff0553f1495a8a841050a40098ab",
            "f52dda44340a41abb4ddd7c89cb33ab9",
            "8b6b4f8e17f04ef291f24cc25cf72506",
            "020d8500617b436cb85bc5a346705fae",
            "8f4afe235df54a6aacc8af89cd4557b7",
            "d6819a68428d490ca31235f11e9d0e43",
            "acb49c04e52b4e9ca24f24c3a8f3b819",
            "8bd6109dd5e6429ea7a49c2e23f33b5e",
            "ef447fa8225f4ddda94d110dc891feaa",
            "22d49e4bcebf4224b0c2c390eae5088e",
            "de9bc625609043858d561ad9a650d282",
            "b8e440efcf8947d297d0d2a1abbf0233",
            "6ed8ab7af07a4a53b7d415e71fa120ce",
            "6449fdbf8959455989e68639fa7cc9ea",
            "6c97052fea584b79821f5a6e6915ac3b",
            "d4891bdbe6ff412bae6873d0300fcf00",
            "10e2bdc34b13497badfab9acb79ff318",
            "a34c1826b46649a78c74844301033f06",
            "0d36af3d9841450e9efabafb3cfa4a45",
            "a2c4a01f391a4d0da9d62fa39d04b011",
            "efcad136d8964a2888f20023bb62d40e",
            "7a4ebf3b6d9f429b9f384319ab5678a1",
            "ed5a35b0b96042ceb1afbf8defa7e570",
            "7ec8d3122058484e8058c864a87bbdfd",
            "84d5a4b1c62e4eb4a707f112637725a4",
            "6837334c5bdb468aaaf463e88010ed35",
            "fe28e523cbf642b3bad8ccb5161b5ad5",
            "077aa6429a3244a893129a24e6b9a36c"
          ]
        },
        "collapsed": true,
        "id": "N1m-UM1RQMzz",
        "outputId": "dd2dd040-205e-451f-84bf-4be20b45298c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4fd3468a21c4ae5bed31ebcfe6cd77a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/936 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acb49c04e52b4e9ca24f24c3a8f3b819",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/485M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a34c1826b46649a78c74844301033f06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/412 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TimesformerForVideoClassification(\n",
              "  (timesformer): TimesformerModel(\n",
              "    (embeddings): TimesformerEmbeddings(\n",
              "      (patch_embeddings): TimesformerPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (time_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): TimesformerEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x TimesformerLayer(\n",
              "          (drop_path): Identity()\n",
              "          (attention): TimeSformerAttention(\n",
              "            (attention): TimesformerSelfAttention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TimesformerSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TimesformerIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TimesformerOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (temporal_attention): TimeSformerAttention(\n",
              "            (attention): TimesformerSelfAttention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TimesformerSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "action_model = AutoModelForVideoClassification.from_pretrained(MODEL_PATH)\n",
        "image_processor = AutoImageProcessor.from_pretrained(MODEL_PATH)\n",
        "action_model.to(device)\n",
        "action_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Execution Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWUHpa87Q6BZ",
        "outputId": "fafe78f3-3bab-47b0-abee-64c4726ae035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memulai pelacakan orang...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lap>=0.5.12'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.8s\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "video 1/1 (frame 1/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 240.0ms\n",
            "video 1/1 (frame 2/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 34.7ms\n",
            "video 1/1 (frame 3/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 29.7ms\n",
            "video 1/1 (frame 4/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 53.0ms\n",
            "video 1/1 (frame 5/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 33.5ms\n",
            "video 1/1 (frame 6/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 21.9ms\n",
            "video 1/1 (frame 7/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 19.9ms\n",
            "video 1/1 (frame 8/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 26.9ms\n",
            "video 1/1 (frame 9/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 46.5ms\n",
            "video 1/1 (frame 10/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 33.2ms\n",
            "video 1/1 (frame 11/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 24.9ms\n",
            "video 1/1 (frame 12/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 31.1ms\n",
            "video 1/1 (frame 13/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 35.3ms\n",
            "video 1/1 (frame 14/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 27.8ms\n",
            "video 1/1 (frame 15/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 30.8ms\n",
            "video 1/1 (frame 16/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 36.2ms\n",
            "video 1/1 (frame 17/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 55.3ms\n",
            "video 1/1 (frame 18/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 41.6ms\n",
            "video 1/1 (frame 19/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 35.6ms\n",
            "video 1/1 (frame 20/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 31.5ms\n",
            "video 1/1 (frame 21/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 22.2ms\n",
            "video 1/1 (frame 22/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 30.0ms\n",
            "video 1/1 (frame 23/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 24.4ms\n",
            "video 1/1 (frame 24/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 21.7ms\n",
            "video 1/1 (frame 25/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 20.1ms\n",
            "video 1/1 (frame 26/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 16.7ms\n",
            "video 1/1 (frame 27/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 15.4ms\n",
            "video 1/1 (frame 28/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 14.4ms\n",
            "video 1/1 (frame 29/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 15.9ms\n",
            "video 1/1 (frame 30/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 16.1ms\n",
            "video 1/1 (frame 31/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 15.8ms\n",
            "video 1/1 (frame 32/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 13.8ms\n",
            "video 1/1 (frame 33/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.3ms\n",
            "video 1/1 (frame 34/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.0ms\n",
            "video 1/1 (frame 35/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.8ms\n",
            "video 1/1 (frame 36/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.8ms\n",
            "video 1/1 (frame 37/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 15.3ms\n",
            "video 1/1 (frame 38/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 16.5ms\n",
            "video 1/1 (frame 39/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.5ms\n",
            "video 1/1 (frame 40/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 18.3ms\n",
            "video 1/1 (frame 41/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 15.3ms\n",
            "video 1/1 (frame 42/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 18.2ms\n",
            "video 1/1 (frame 43/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.9ms\n",
            "video 1/1 (frame 44/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.1ms\n",
            "video 1/1 (frame 45/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.0ms\n",
            "video 1/1 (frame 46/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 23.5ms\n",
            "video 1/1 (frame 47/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 13.9ms\n",
            "video 1/1 (frame 48/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 16.8ms\n",
            "video 1/1 (frame 49/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 17.2ms\n",
            "video 1/1 (frame 50/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 18.3ms\n",
            "video 1/1 (frame 51/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.4ms\n",
            "video 1/1 (frame 52/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 18.3ms\n",
            "video 1/1 (frame 53/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.4ms\n",
            "video 1/1 (frame 54/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 13.2ms\n",
            "video 1/1 (frame 55/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 15.2ms\n",
            "video 1/1 (frame 56/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 15.9ms\n",
            "video 1/1 (frame 57/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 15.4ms\n",
            "video 1/1 (frame 58/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 21.9ms\n",
            "video 1/1 (frame 59/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.8ms\n",
            "video 1/1 (frame 60/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 21.9ms\n",
            "video 1/1 (frame 61/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 13.8ms\n",
            "video 1/1 (frame 62/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 18.0ms\n",
            "video 1/1 (frame 63/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.6ms\n",
            "video 1/1 (frame 64/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.7ms\n",
            "video 1/1 (frame 65/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 15.7ms\n",
            "video 1/1 (frame 66/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 15.3ms\n",
            "video 1/1 (frame 67/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 14.8ms\n",
            "video 1/1 (frame 68/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 14.1ms\n",
            "video 1/1 (frame 69/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 14 persons, 15.8ms\n",
            "video 1/1 (frame 70/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 23.0ms\n",
            "video 1/1 (frame 71/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 14.2ms\n",
            "video 1/1 (frame 72/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 25.2ms\n",
            "video 1/1 (frame 73/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 14.5ms\n",
            "video 1/1 (frame 74/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 28.1ms\n",
            "video 1/1 (frame 75/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 16.9ms\n",
            "video 1/1 (frame 76/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 17.6ms\n",
            "video 1/1 (frame 77/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 18.1ms\n",
            "video 1/1 (frame 78/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 16.0ms\n",
            "video 1/1 (frame 79/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 18.5ms\n",
            "video 1/1 (frame 80/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 12.6ms\n",
            "video 1/1 (frame 81/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 14.6ms\n",
            "video 1/1 (frame 82/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 14 persons, 15.8ms\n",
            "video 1/1 (frame 83/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 14 persons, 13.4ms\n",
            "video 1/1 (frame 84/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 14.5ms\n",
            "video 1/1 (frame 85/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 13.5ms\n",
            "video 1/1 (frame 86/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 14.2ms\n",
            "video 1/1 (frame 87/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 13.9ms\n",
            "video 1/1 (frame 88/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 16.4ms\n",
            "video 1/1 (frame 89/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 14.4ms\n",
            "video 1/1 (frame 90/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 14.8ms\n",
            "video 1/1 (frame 91/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 17.1ms\n",
            "video 1/1 (frame 92/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 17.4ms\n",
            "video 1/1 (frame 93/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 15.0ms\n",
            "video 1/1 (frame 94/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 18.3ms\n",
            "video 1/1 (frame 95/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 15.8ms\n",
            "video 1/1 (frame 96/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 21.3ms\n",
            "video 1/1 (frame 97/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 18.6ms\n",
            "video 1/1 (frame 98/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 22.5ms\n",
            "video 1/1 (frame 99/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 13.6ms\n",
            "video 1/1 (frame 100/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 15.6ms\n",
            "video 1/1 (frame 101/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 15.1ms\n",
            "video 1/1 (frame 102/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 19.5ms\n",
            "video 1/1 (frame 103/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 24.4ms\n",
            "video 1/1 (frame 104/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 19.9ms\n",
            "video 1/1 (frame 105/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 18.4ms\n",
            "video 1/1 (frame 106/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 17.4ms\n",
            "video 1/1 (frame 107/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.1ms\n",
            "video 1/1 (frame 108/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.0ms\n",
            "video 1/1 (frame 109/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 12.8ms\n",
            "video 1/1 (frame 110/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 17.6ms\n",
            "video 1/1 (frame 111/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 19.1ms\n",
            "video 1/1 (frame 112/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.9ms\n",
            "video 1/1 (frame 113/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 34.7ms\n",
            "video 1/1 (frame 114/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 15.5ms\n",
            "video 1/1 (frame 115/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 19.8ms\n",
            "video 1/1 (frame 116/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 14.8ms\n",
            "video 1/1 (frame 117/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 7 persons, 18.8ms\n",
            "video 1/1 (frame 118/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 6 persons, 25.0ms\n",
            "video 1/1 (frame 119/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 6 persons, 16.1ms\n",
            "video 1/1 (frame 120/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 6 persons, 14.8ms\n",
            "video 1/1 (frame 121/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 7 persons, 18.2ms\n",
            "video 1/1 (frame 122/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 15.9ms\n",
            "video 1/1 (frame 123/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 14.8ms\n",
            "video 1/1 (frame 124/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 7 persons, 21.6ms\n",
            "video 1/1 (frame 125/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 7 persons, 15.1ms\n",
            "video 1/1 (frame 126/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 7 persons, 14.1ms\n",
            "video 1/1 (frame 127/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 19.0ms\n",
            "video 1/1 (frame 128/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 17.0ms\n",
            "video 1/1 (frame 129/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 17.9ms\n",
            "video 1/1 (frame 130/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 13.4ms\n",
            "video 1/1 (frame 131/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 15.5ms\n",
            "video 1/1 (frame 132/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 47.5ms\n",
            "video 1/1 (frame 133/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 14.5ms\n",
            "video 1/1 (frame 134/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 22.5ms\n",
            "video 1/1 (frame 135/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 14 persons, 15.0ms\n",
            "video 1/1 (frame 136/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 15.5ms\n",
            "video 1/1 (frame 137/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 14.5ms\n",
            "video 1/1 (frame 138/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 14.9ms\n",
            "video 1/1 (frame 139/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 13.4ms\n",
            "video 1/1 (frame 140/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 47.8ms\n",
            "video 1/1 (frame 141/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 27.7ms\n",
            "video 1/1 (frame 142/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 40.8ms\n",
            "video 1/1 (frame 143/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 67.6ms\n",
            "video 1/1 (frame 144/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 30.2ms\n",
            "video 1/1 (frame 145/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 39.1ms\n",
            "video 1/1 (frame 146/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 45.0ms\n",
            "video 1/1 (frame 147/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 37.0ms\n",
            "video 1/1 (frame 148/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 51.7ms\n",
            "video 1/1 (frame 149/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 32.5ms\n",
            "video 1/1 (frame 150/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 41.6ms\n",
            "video 1/1 (frame 151/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 35.6ms\n",
            "video 1/1 (frame 152/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 31.9ms\n",
            "video 1/1 (frame 153/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 51.5ms\n",
            "video 1/1 (frame 154/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 35.3ms\n",
            "video 1/1 (frame 155/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 39.6ms\n",
            "video 1/1 (frame 156/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 53.9ms\n",
            "video 1/1 (frame 157/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 47.2ms\n",
            "video 1/1 (frame 158/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 43.8ms\n",
            "video 1/1 (frame 159/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 46.4ms\n",
            "video 1/1 (frame 160/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 45.2ms\n",
            "video 1/1 (frame 161/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 13.3ms\n",
            "video 1/1 (frame 162/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 33.3ms\n",
            "video 1/1 (frame 163/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 13.6ms\n",
            "video 1/1 (frame 164/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 13.4ms\n",
            "video 1/1 (frame 165/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.8ms\n",
            "video 1/1 (frame 166/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 12.9ms\n",
            "video 1/1 (frame 167/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.2ms\n",
            "video 1/1 (frame 168/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.4ms\n",
            "video 1/1 (frame 169/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 15.3ms\n",
            "video 1/1 (frame 170/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 12.4ms\n",
            "video 1/1 (frame 171/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.7ms\n",
            "video 1/1 (frame 172/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.2ms\n",
            "video 1/1 (frame 173/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.0ms\n",
            "video 1/1 (frame 174/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 19.1ms\n",
            "video 1/1 (frame 175/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 18.0ms\n",
            "video 1/1 (frame 176/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 13.2ms\n",
            "video 1/1 (frame 177/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 13.4ms\n",
            "video 1/1 (frame 178/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 19.8ms\n",
            "video 1/1 (frame 179/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 13.6ms\n",
            "video 1/1 (frame 180/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 15.8ms\n",
            "video 1/1 (frame 181/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 12.7ms\n",
            "video 1/1 (frame 182/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 15.6ms\n",
            "video 1/1 (frame 183/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 14.5ms\n",
            "video 1/1 (frame 184/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 25.3ms\n",
            "video 1/1 (frame 185/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 15.8ms\n",
            "video 1/1 (frame 186/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 15.7ms\n",
            "video 1/1 (frame 187/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 13.4ms\n",
            "video 1/1 (frame 188/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 18.1ms\n",
            "video 1/1 (frame 189/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 20.8ms\n",
            "video 1/1 (frame 190/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 14.9ms\n",
            "video 1/1 (frame 191/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 18.4ms\n",
            "video 1/1 (frame 192/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 15.2ms\n",
            "video 1/1 (frame 193/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 21.7ms\n",
            "video 1/1 (frame 194/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 20.5ms\n",
            "video 1/1 (frame 195/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 14 persons, 14.4ms\n",
            "video 1/1 (frame 196/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 18.9ms\n",
            "video 1/1 (frame 197/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 13.0ms\n",
            "video 1/1 (frame 198/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 15.7ms\n",
            "video 1/1 (frame 199/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 17.0ms\n",
            "video 1/1 (frame 200/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 14.0ms\n",
            "video 1/1 (frame 201/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 31.9ms\n",
            "video 1/1 (frame 202/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 41.9ms\n",
            "video 1/1 (frame 203/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 30.9ms\n",
            "video 1/1 (frame 204/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 42.7ms\n",
            "video 1/1 (frame 205/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 30.9ms\n",
            "video 1/1 (frame 206/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 44.3ms\n",
            "video 1/1 (frame 207/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 27.9ms\n",
            "video 1/1 (frame 208/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 40.1ms\n",
            "video 1/1 (frame 209/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 31.0ms\n",
            "video 1/1 (frame 210/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 26.0ms\n",
            "video 1/1 (frame 211/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 37.4ms\n",
            "video 1/1 (frame 212/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 44.3ms\n",
            "video 1/1 (frame 213/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 30.2ms\n",
            "video 1/1 (frame 214/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 14 persons, 34.7ms\n",
            "video 1/1 (frame 215/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 13 persons, 35.4ms\n",
            "video 1/1 (frame 216/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 16.1ms\n",
            "video 1/1 (frame 217/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 29.7ms\n",
            "video 1/1 (frame 218/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 12 persons, 41.4ms\n",
            "video 1/1 (frame 219/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 26.1ms\n",
            "video 1/1 (frame 220/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 25.3ms\n",
            "video 1/1 (frame 221/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 23.8ms\n",
            "video 1/1 (frame 222/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 48.7ms\n",
            "video 1/1 (frame 223/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 26.9ms\n",
            "video 1/1 (frame 224/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 25.4ms\n",
            "video 1/1 (frame 225/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 44.5ms\n",
            "video 1/1 (frame 226/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 31.6ms\n",
            "video 1/1 (frame 227/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 17.3ms\n",
            "video 1/1 (frame 228/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 44.9ms\n",
            "video 1/1 (frame 229/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 27.2ms\n",
            "video 1/1 (frame 230/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 29.3ms\n",
            "video 1/1 (frame 231/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 40.9ms\n",
            "video 1/1 (frame 232/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 35.8ms\n",
            "video 1/1 (frame 233/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 32.0ms\n",
            "video 1/1 (frame 234/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 48.2ms\n",
            "video 1/1 (frame 235/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 37.6ms\n",
            "video 1/1 (frame 236/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 34.5ms\n",
            "video 1/1 (frame 237/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 33.7ms\n",
            "video 1/1 (frame 238/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 26.3ms\n",
            "video 1/1 (frame 239/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 25.0ms\n",
            "video 1/1 (frame 240/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 23.6ms\n",
            "video 1/1 (frame 241/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 49.3ms\n",
            "video 1/1 (frame 242/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 36.1ms\n",
            "video 1/1 (frame 243/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 52.4ms\n",
            "video 1/1 (frame 244/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 49.0ms\n",
            "video 1/1 (frame 245/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 65.1ms\n",
            "video 1/1 (frame 246/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 55.2ms\n",
            "video 1/1 (frame 247/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 31.1ms\n",
            "video 1/1 (frame 248/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 53.7ms\n",
            "video 1/1 (frame 249/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 48.6ms\n",
            "video 1/1 (frame 250/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 24.4ms\n",
            "video 1/1 (frame 251/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 36.8ms\n",
            "video 1/1 (frame 252/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 39.9ms\n",
            "video 1/1 (frame 253/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 28.3ms\n",
            "video 1/1 (frame 254/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 36.5ms\n",
            "video 1/1 (frame 255/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 9 persons, 37.5ms\n",
            "video 1/1 (frame 256/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 8 persons, 47.4ms\n",
            "video 1/1 (frame 257/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 54.7ms\n",
            "video 1/1 (frame 258/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 10 persons, 38.2ms\n",
            "video 1/1 (frame 259/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 36.0ms\n",
            "video 1/1 (frame 260/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 43.0ms\n",
            "video 1/1 (frame 261/261) /content/drive/MyDrive/datathon_2025/videos/multiperson.mp4: 384x640 11 persons, 43.5ms\n",
            "Speed: 5.2ms preprocess, 25.7ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "62 orang berhasil dilacak.\n",
            "Memulai klasifikasi aksi mentah...\n",
            "Klasifikasi mentah selesai.\n",
            "Membersihkan dan menggabungkan prediksi aksi...\n",
            "Menyimpan rekap aksi ke /content/rekap_multiperson.csv...\n",
            "Rekap aksi berhasil disimpan.\n",
            "Membuat video output dengan anotasi...\n",
            "Video output berhasil dibuat!\n",
            "\n",
            "--- Hasil Akhir ---\n",
            "Video output disimpan di: /content/corner_multiperson_prediction.mp4\n",
            "Rekap aksi disimpan di: /content/rekap_multiperson.csv\n",
            "\n",
            "Menampilkan video hasil:\n",
            "\n",
            "Isi file rekap aksi (/content/rekap_multiperson.csv):\n",
            "Action,Count\n",
            "Background,11\n",
            "Hand In Shelf,34\n",
            "Inspect Product,34\n",
            "Inspect Shelf,6\n",
            "Reach To Shelf,14\n",
            "Retract From Shelf,11\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if 'action_model' in locals() and os.path.exists(input_video_path):\n",
        "    predict_multiperson_video(\n",
        "        video_path=input_video_path,\n",
        "        output_path=output_video_path,\n",
        "        yolo=yolo_model,\n",
        "        action_classifier=action_model,\n",
        "        processor=image_processor,\n",
        "        device=device,\n",
        "        output_csv_path=output_csv_path\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Hasil Akhir ---\")\n",
        "    print(f\"Video output disimpan di: {output_video_path}\")\n",
        "    print(f\"Rekap aksi disimpan di: {output_csv_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"Eksekusi dibatalkan. Pastikan model telah dimuat dan path video input benar.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JIKA PAKAI COLAB: Tampilkan video hasil\n",
        "print(\"\\nMenampilkan video hasil:\")\n",
        "mp4 = open(output_video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "# Tampilkan isi file CSV\n",
        "if os.path.exists(output_csv_path):\n",
        "    print(f\"\\nIsi file rekap aksi ({output_csv_path}):\")\n",
        "    with open(output_csv_path, 'r') as f:\n",
        "        print(f.read())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "020d8500617b436cb85bc5a346705fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "077aa6429a3244a893129a24e6b9a36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d36af3d9841450e9efabafb3cfa4a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5a35b0b96042ceb1afbf8defa7e570",
            "placeholder": "​",
            "style": "IPY_MODEL_7ec8d3122058484e8058c864a87bbdfd",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "10e2bdc34b13497badfab9acb79ff318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d49e4bcebf4224b0c2c390eae5088e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4891bdbe6ff412bae6873d0300fcf00",
            "placeholder": "​",
            "style": "IPY_MODEL_10e2bdc34b13497badfab9acb79ff318",
            "value": " 485M/485M [00:07&lt;00:00, 30.6MB/s]"
          }
        },
        "4d63ff0553f1495a8a841050a40098ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6370bef713af40b1a51158378fe6ec02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b6b4f8e17f04ef291f24cc25cf72506",
            "max": 936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_020d8500617b436cb85bc5a346705fae",
            "value": 936
          }
        },
        "63ecf458d5584859aebd5606183e9569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4afe235df54a6aacc8af89cd4557b7",
            "placeholder": "​",
            "style": "IPY_MODEL_d6819a68428d490ca31235f11e9d0e43",
            "value": " 936/936 [00:00&lt;00:00, 94.2kB/s]"
          }
        },
        "6449fdbf8959455989e68639fa7cc9ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6837334c5bdb468aaaf463e88010ed35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c97052fea584b79821f5a6e6915ac3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ed8ab7af07a4a53b7d415e71fa120ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a4ebf3b6d9f429b9f384319ab5678a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec8d3122058484e8058c864a87bbdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d5a4b1c62e4eb4a707f112637725a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b6b4f8e17f04ef291f24cc25cf72506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd6109dd5e6429ea7a49c2e23f33b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e440efcf8947d297d0d2a1abbf0233",
            "placeholder": "​",
            "style": "IPY_MODEL_6ed8ab7af07a4a53b7d415e71fa120ce",
            "value": "model.safetensors: 100%"
          }
        },
        "8f4afe235df54a6aacc8af89cd4557b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c4a01f391a4d0da9d62fa39d04b011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d5a4b1c62e4eb4a707f112637725a4",
            "max": 412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6837334c5bdb468aaaf463e88010ed35",
            "value": 412
          }
        },
        "a34c1826b46649a78c74844301033f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d36af3d9841450e9efabafb3cfa4a45",
              "IPY_MODEL_a2c4a01f391a4d0da9d62fa39d04b011",
              "IPY_MODEL_efcad136d8964a2888f20023bb62d40e"
            ],
            "layout": "IPY_MODEL_7a4ebf3b6d9f429b9f384319ab5678a1"
          }
        },
        "a5fa8af208ea4c08bfd926138d1a7555": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d63ff0553f1495a8a841050a40098ab",
            "placeholder": "​",
            "style": "IPY_MODEL_f52dda44340a41abb4ddd7c89cb33ab9",
            "value": "config.json: 100%"
          }
        },
        "acb49c04e52b4e9ca24f24c3a8f3b819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bd6109dd5e6429ea7a49c2e23f33b5e",
              "IPY_MODEL_ef447fa8225f4ddda94d110dc891feaa",
              "IPY_MODEL_22d49e4bcebf4224b0c2c390eae5088e"
            ],
            "layout": "IPY_MODEL_de9bc625609043858d561ad9a650d282"
          }
        },
        "ad65c5c0f1fa48e8816ee95297e1fac9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e440efcf8947d297d0d2a1abbf0233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4891bdbe6ff412bae6873d0300fcf00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4fd3468a21c4ae5bed31ebcfe6cd77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5fa8af208ea4c08bfd926138d1a7555",
              "IPY_MODEL_6370bef713af40b1a51158378fe6ec02",
              "IPY_MODEL_63ecf458d5584859aebd5606183e9569"
            ],
            "layout": "IPY_MODEL_ad65c5c0f1fa48e8816ee95297e1fac9"
          }
        },
        "d6819a68428d490ca31235f11e9d0e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9bc625609043858d561ad9a650d282": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5a35b0b96042ceb1afbf8defa7e570": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef447fa8225f4ddda94d110dc891feaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6449fdbf8959455989e68639fa7cc9ea",
            "max": 485084560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c97052fea584b79821f5a6e6915ac3b",
            "value": 485084560
          }
        },
        "efcad136d8964a2888f20023bb62d40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe28e523cbf642b3bad8ccb5161b5ad5",
            "placeholder": "​",
            "style": "IPY_MODEL_077aa6429a3244a893129a24e6b9a36c",
            "value": " 412/412 [00:00&lt;00:00, 28.0kB/s]"
          }
        },
        "f52dda44340a41abb4ddd7c89cb33ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe28e523cbf642b3bad8ccb5161b5ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
